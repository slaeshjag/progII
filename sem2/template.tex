%% En enkel mall för att skapa en labb-raport.
\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc} 
\usepackage[swedish]{babel}

\title{Seminarie 2}
\author{Steven Arnow}
\date{\today} 

\begin{document}

\maketitle 

\section{Uppgiften}

Uppgiften går ut på att implementera en huffmankodare/avkodare, samt kod för att generera kodträdet som används av de två. Dessutom ska implementationen benchmarkas. Uppgiften skall lösas genom att göra frekvensanalys av indata, för att konstruera ett träd som kodar förekommande tecken för optimal komprimering. 

\section{Ansatts}

Jag implementerade detta genom att först skapa en sorterad lista av indata, och med hjälp av den skapa en lista med förekomsten av alla möjliga bytes. Med frekvenslistan skapade jag sedan en lista med löv till det kommande trädet. Med lövlistan och frekvenslistan itererar jag sedan över löven, och grupperar upp dom i två löv som sitter fast i en gren. Detta körs tills ett löv/gren med högre frekvens än den tidigare hittas. Då läggs kvarvarande löv/grenar in i listan med behandlade trädbitar, som då sorteras efter frekvens och skickas tillbaka i rekursionen som indata. Detta upprepas tills endast en rot finns kvar.

Därefter skapas en lista med koder för varje möjlig byte utifrån trädet, detta görs genom att bygga upp en osorterad lista vartefter trädet rekursivt utforskas. När rekursionen faller tillbaka byggs en lista upp av vägarna som togs för att hitta varje löv. I och med hur listan byggs upp hamnar dessutom de vanligast förekommande elementen först.

Med hjälp av listan kan indata lätt kodas efter huffmanträdet, och med huffmanträdet kan utdata snabbt konverteras tillbaka till vad det ursprungligen var som komprimerades.

\section{Utvärdering}

Jag har vid körningarna använt IRC-loggar från en engelskspråklig IRC-kanal. Detta innebär att teckenfrekvensen ligger ganska nära engelska för indatan, men att det fortfarande finns lite småjobbiga tecken här och var från när någon skrivit på ett annat språk. Som det går att se i tabell \ref{tab:results} så är komprimeringsration ganska konstant mellan de olika datamängderna. Vilket är att förvänta sig när språket och kommunikationsmediet är detsamma. Som även går att se i tabell \ref{tab:results2} så är behandlingshastigheten väldigt lik. Någon statistisk säkerhet är inte fastställd, så någon trend kan inte fastställas från variationerna, annat än att den ser \emph{ganska} linjär ut vid de prövade datastorlekarna. Det kan ju vara så att större datamängder innehåller fler udda tecken, och därmed påverkar huffmanträdets struktur.

Uppgifterna i denna kurs kanske inte kräver en utvärdering men man kan
här visa resultat från testkörningar mm. Om man vill lägga in resultat
från testkörningar kan man sammanfatta dessa i en tabell. Ett exempel
kan ses i tabell \ref{tab:results}. 


\begin{table}
\centering
\begin{tabular}{|l|r|r|r|r|}  
\hline
Skapa tabell (ms) & Koda data (ms) & Avkoda data (ms) & datastorlek (ko) & komprimeringsratio\\
\hline
51.8 & 82.4 & 3.5 & 16 & 0.644\\
\hline
164 & 330 & 14 & 64 & 0.637\\
\hline
1405 & 1573 & 112 & 512 & 0.639\\
\hline
11668 & 20062 & 921 & 4096 & 0.636\\
\hline
\end{tabular}
\caption{Tid för olika steg i komprimeringen vs. datastorlek. IRC-loggar som indata}
\label{tab:results}
\end{table}

\begin{table}
\centering
\begin{tabular}{|l|r|r|r|}  
\hline
Trädgenerering (ko/s) & Datakodning (ko/s) & Dataavkodning (ko/s) & Datastorlek (ko)\\
\hline
316 & 199 & 4707 & 16\\
\hline
400 & 198 & 4759 & 64\\
\hline
373 & 333 & 4673 & 512\\
\hline
360 & 209 & 4551 & 4096\\
\hline
\end{tabular}
\caption{Behandlingshastighet kodning/avkodning relativt indatastorlek.}
\label{tab:results2}
\end{table}


Om annan indata skulle ha använts skulle ev. både behandligshastighet och komprimeringsratio ändras. Ett mindre alfabet (fler av färre tecken) skulle ge upphov till bättre komprimering, eftersom kortare koder kan användas för en större del av alla tecken. Och andra sidan skulle homogent brus ge upphov till mycket sämre komprimeringsratio, eftersom inget tecken statistiskt sett förekommer oftare än andra. Är skalan 0..255 på sagda brus så kommer komrimeringsration lägga sig över 1.0 med huffmantabellens storlek inräknad. Excl. huffmantabellen så skulle homogent brus ge exakt 1.0, då det resulterande trädet skulle bli perfekt balanserat.



\section{Sammanfattning}

Att implementera trädet för huffmankodningen var i sig inte så problematiskt. Teorin är rätt enkel. Implementationen var dock värre. Min egna ovana gjorde sig påmind när 16 rader kod som skulle tagit mig 10 minuter att skriva i C tog över 2 timmar i erlang. Detta kombinerat med begränsad debuggingvana i Erlang gjorde felsökning väldigt tidskrävande. Specifika implementationsproblem var träduppbyggnaden. Koden blev inte fullt så läsbar som jag hade önskat, och trädet som byggdes var först i stort sett en länkad lista med en lövgren på varje nog, och därefter ett perfekt balanserat träd som gav noll komprimering. Tankevurporna hittades dock, som kan ses av kompremeringsration, i och med add den ligger på rätt sida av ettan.

Annars var det bara syntax och typfel det sket sig på, främst då jag inte har tillräckligt många fotpedaler eller modifier keys för att kunna byta till Escape Meta Alt Control Shift.


\end{document}
